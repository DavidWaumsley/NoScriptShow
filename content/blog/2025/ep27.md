---
title: "Enshittification: Why We Need Independent Websites"
description: What we need to know before launching a pay-per-click campaign.
date: 2026-01-07
tags: ["chat"]
permalink: "/27/{{slugify }}/"
videoid: 4O88U1pWLoA
---

**Show Notes:**

Here's the presentation slides. Below this is the text version with notes not included on the slides.

<embed class="full" src="\pdf\Enshittification.pdf" title="Episode slides" type="application/pdf" width="100%" height="600px" />


## Introduction

- Borrowed from Cory Doctorow’s 2025 book “Enshittification: Why Everything Suddenly Got Worse and What to Do About It”.
- 2025 marked a shift from seeing the internet as empowering to seeing it as unhealthy.
- Australia banned social media for under 16-year-olds.
- “Slop” became Merriam-Webster’s Word of the Year, referring to low-quality AI-generated content.
- Trust in digital services declined, AI faced backlash, and concerns about mental health and the internet grew.

## The Current State of Web Development

- Most website creators have been doing it for less than 6 years.
- Many learned via commercial platforms rather than through the W3C.
- “Vibe coding” got most of the attention.
- This seems magical, but controlled by wealthy techno‑optimists.

### Critical Voices

- Ed Zitron’s podcast and newsletter: https://www.betteroffline.com
- Carl Brown’s YouTube channel: https://www.youtube.com/@InternetOfBugs

## Key Authors and Perspectives

### Cory Doctorow – “Enshittification”

- Canadian‑British author and journalist.
- Has spent 25 years advocating for digital rights, copyright reform, and technology policy.
- “Enshittification” was Macquarie Dictionary’s Word of the Year for 2024.
- Book published in late 2025.
- Not anti‑AI; argues AI should be “socialised” like the web.

### Karen Hao – “Empire of AI: Dreams and Nightmares in Sam Altman’s OpenAI”

- Book published in May 2025.
- Former Chinese tech reporter for The Wall Street Journal and senior AI editor at MIT Technology Review.
- Previously an application engineer at a Google X spin‑off.
- Shows how fragile AI and its key players are and the quasi‑religious fervour around AI.
- Argues ChatGPT was OpenAI’s last hope after past failures.
- Focuses on human and environmental costs of surveillance capitalism.

### Yanis Varoufakis – “Technofeudalism”

- Greek economist, politician and UK professor.
- Book published in 2023.
- Argues that “Cloud Capital” owned by platforms like Google, Meta and Amazon turned people into “cloud serfs”.
- People effectively volunteered to become renters.

### Ed Zitron – Tech Commentator

- British tech commentator.
- Critic of “growth‑at‑all‑costs” culture in tech.
- Highlights its high cost and limited real‑world problem solving.

### Carl Brown – Software Engineer

- Software engineer with about 35 years of experience.
- Critical of AI in software development.

### Tim Berners‑Lee – “This Is for Everyone”

- Book published in September 2025.
- Explains how the web was created on top of others’ work.
- Describes the struggle to keep the web in public ownership.
- Critical of unregulated algorithmic control.

## Three Stages of Enshittification

1. **Lure Users**: Offer a valuable service, often at a loss, to attract a large user base.

2. **Lure Business**:Shift value away from users toward business customers (advertisers, publishers) to monetise.

3. **Extract Everything**: Once businesses are dependent, extract value from both users and businesses and raise fees and degrade service.

### Financial Dynamics

Stage 3 benefits shareholders and investors short‑term, but Stock buybacks are used to inflate perceived value while effectively looting the company.

Ed Zitron’s “Enshittifinancial Crisis” discusses:

  - Changing depreciation values of GPU stocks.
  - Valuations based on intent rather than contracts.
  - Misleading narratives about AI‑driven layoffs.
  - Circular investments (e.g., Oracle, Nvidia, OpenAI).

Doctorow and Zitron don't see how OpenAI cab survive. No government could bail out the trillions needed even if profitability were possible.

## Three Examples

### Facebook

- Attracted users with privacy and friend‑centric feeds.
- Shifted focus to publishers.
- Now prioritises boosted posts over organic content.
- Procter & Gamble cut a $200 million/year Facebook ad budget and saw no loss in sales.
- Early on, Facebook warned MySpace users about Rupert Murdoch’s ownership while later becoming a similar surveillance platform.

### Amazon

- Initially subsidised goods and shipping.
- Search results now dominated by “pay‑to‑play” ads.
- Seller fees can exceed 45% of the sale price.
- Sellers are contractually prevented from offering lower prices elsewhere, so users ultimately pay the platform’s margin.
- The Diapers.com acquisition signalled that competitors would be undercut until they sold.

### Google Search

- Was known for highly relevant results.
- Results worsened to increase search time and show more ads.
- Alternative engines like Kagi show what Google’s data can do without ad‑driven friction.
- Google originally supported free academic thought.
- With AI, scientific constraints began to conflict with fundraising goals.

## The Enshittiverse

- Removes interoperability.
- Weakens antitrust.
- Reduces worker power.

### Removing Interoperability

- Locks in user data, especially on social media.
- Prevents tampering with devices and buying supplies on the open market (e.g., printer ink).
- Uses DMCA Section 1201, which criminalises bypassing digital locks.
- Smart TVs are often sold at a loss and monetised via surveillance.
- Companies prefer apps to websites because apps can more easily bypass privacy regulations like GDPR.
- Uber can: Charge higher prices if a customer’s battery is low. Lower driver pay if they accept rides “too quickly” too often.

### Weakening Antitrust

- Antitrust enforcement weakened since Nixon, with some tightening under Biden.
- Many of Google’s innovations were acquired rather than built in‑house.
- Marc Andreessen is a prominent techno‑optimist and influential conduit between Silicon Valley and political power.
- Trump has proposed a 10‑year ban on state and local AI regulations.

### Reducing Worker Power

- Apple’s use of Foxconn includes stories of suicide nets to prevent worker deaths.
- Journalist Oobah Butler exposed Amazon drivers resorting to urinating in bottles due to relentless schedules, then selling “driver urine” on Amazon as a prank.
- Companies deploy extensive tactics to discourage unionisation.
- Karen Hao documents how AI depends on low‑wage, hidden labour. For example, Kenyan contractors for OpenAI moderating violent and sexual content developed PTSD.

## The Vibe Coding Hype of 2025

### Timeline

- **February**: Andrej Karpathy coins “vibe coding” in a viral X post.
- **March**: Merriam‑Webster adds the term as a “slang & trending” entry.
- **July**: Y Combinator notes 25% of its Winter batch companies use codebases that are 95% AI‑generated.
- **September**: Major tech outlets report a “vibe coding hangover” as senior engineers struggle with brittle codebases.

### Tools and Business Model

- Tools: Cursor Composer, Replit Agent, Lovable, Bolt and others.
- Many have strong revenues, but only Replit shows a profit.
- All pay significant fees to foundational providers (Google, NVIDIA, OpenAI), while competing with those providers’ own coding tools.
- Raises the question of whether these companies can escape their own version of enshittification or whether they are “techno‑serfs”.

### Technical Reality

- Experienced developers note that about 80% of development is problem‑solving, not typing code.
- LLMs operate on probability; each prompt is akin to pulling a slot machine lever.
- This makes iterative, agile development hard when the system re‑writes large portions of code each time.
- Version control becomes difficult when outputs are non‑deterministic.
- GitClear’s analysis of over 211 million lines of code found: An eight‑fold increase in duplicated lines. A doubling of code churn.

## Vibe Coding in 2026

### What Its Proponents Now Say

- Andrej Karpathy built NanoChat largely by hand, saying AI tools were not helpful there.
- Boris Cherny (creator of Claude Code) says vibe coding is fine for throwaway code and prototypes, but not for maintainable code.
- Michel Truell (Cursor CEO) says vibe coding is useful for quick prototypes but unstable for serious applications.

### Good vs Bad Vibe Coding

- Good when: Used by developers who understand how LLMs work and their limitations. Applied to personal tools, experiments and internal utilities.
 
- Bad when: Used by non‑coders for public‑facing websites. Resulting systems are insecure and hard to maintain or migrate.

Several large firms (Amazon, Microsoft, Google, Meta, Tesla) have:
  - Laid off developers.
  - Then rehired for similar roles later, often at lower pay.

## What’s Fueling the AI Hype?

- Monopolistic tech firms need new growth narratives to satisfy investors.
- AGI is framed almost as a religion, enabling imperial expansion of influence and capital.
- Consolidation of power includes undermining democratic oversight and regulation.

### Socioeconomic View

- Doctorow and Zitron stress the problem of needing growth when a company already has a monopoly.
- Karen Hao notes that Sam Altman’s 2013 writing framed founders as religious‑style leaders, not just company builders.
- Techno‑optimists (Musk, Andreessen, Thiel) see democracy as an obstacle to “progress”.
- Many famous tech leaders are investors and fundraisers rather than core inventors.
- Most foundational tech was publicly funded and developed in open contexts.
- Commercial players later took ownership and only “socialise” technology to gain adoption or share losses.
- There are already calls for government backstops as the AI bubble inflates.
- Free social networks raised questions about why investors funded them without clear revenue, given the obvious surveillance value.

## The Web Is for Everyone

### Tim Berners‑Lee’s Web

- The HTTP protocol enabled direct connections between computers without logins.
- Hyperlinks and basic HTML‑style tagging existed, but he made them more powerful and general.
- He worked through the W3C to keep the web in public ownership and evolve it gradually.

### Attempts to Capture the Web

- Marc Andreessen, during the Mosaic era, attempted to pull the web into proprietary directions.
- Ian Hickson of Google led a splinter group (WHATWG) away from W3C, involving Mozilla, Opera and Apple.
- Concerns emerged about accessibility, personal views, and Google’s hidden plans for Chrome.
- This fragmentation helped justify and implement proprietary algorithms and tracking.
- Cambridge Analytica, Brexit and the Trump campaign exemplify how data‑driven manipulation can exploit this environment.
- Policy steps like Australia’s social media ban for minors do not address the underlying commercial incentives.

### New Initiatives

Tim Berners‑Lee’s work at https://www.inrupt.com explores:

  - Web 3.0 concepts rooted in user agency rather than speculation.
  - Solid pods for personal data ownership.
  - Agentic wallets and agents (e.g., “Charlie”) built on open standards.

## Reclaiming Agency as Web Creators

- The web is fundamentally low‑tech; no large third‑party platform is required to build an effective site.
- People can own their data and syndicate copies elsewhere.
- Sites can be designed for human visitors, not algorithms.

### Practical Approaches

- Avoid overspending on websites that then demand constant paid promotion.
- Favour a “dumb” web: Use the rule of least power: simple HTML and CSS first.
- Use static site generators where a site is mostly static.
- Use open‑source tools for dynamic sites, while watching who controls the project.

### IndieWeb and POSSE

- POSSE: Publish (on your) Own Site, Syndicate Elsewhere.
- Post on your own domain first; then automatically share to silos (social platforms).
- Use Webmention and related standards for interaction.
- Hard to completely avoid big tech infrastructure: Example: hosting on Netlify (backed by AWS), editing in VS Code (Microsoft).
- The key is minimising lock‑in rather than achieving perfection.

### AI as a Tool, Not Master

AI is useful for:
  - Translating between programming languages and frameworks.
  - Surface‑level debugging and linting.
  - Supporting graphics and content drafts.
- Environmental impact is real, but worse if human thinking is fully outsourced to a few companies.

## The End or the Start?

The goal is to build sites that:
  - Counter slop with quality.
  - Counter enshittification with ownership.
  - Counter digital feudalism with federation and federation‑friendly tools.
  - Counter AI empires with human creativity, empathy and respect.

### Why Small Sites Still Matter

- The internet’s problems arise from platform monopolies, not from the web’s basic design.
- A “dumb web” approach can restore the early sense of empowerment and global connection.
- About a quarter of businesses still lack a website.
- Even aside from lead generation, the process of creating a simple site and brand can: Clarify purpose and strategy. Provide support and structure in the offline world.


<details> 
<summary>Transcript</summary>


[00:00:05] **Nathan Wrigley:** Hello there and welcome to the No Script Show. Happy New Year. 2025 seemed to be the year when many switched from seeing the internet as an empowering beacon of democracy to something slightly more sinister and unhealthy. It ended with Australia banning social media for the under 16 year olds and slop becoming the word of the year For the Miriam Webster Dictionary, this is referring to the overwhelming flood of low quality AI generated content.

But throughout last year, we've seen a decline in trust of digital services across all sectors and AI backlash and increasing concerns over mental health and the internet. For this first episode of 2026, we're going to try to make sense of this and find the positives for those of us who love the web and building websites to help.

We're borrowing a concept from Corey Doctor's 2025 book entitled and Ification, why Everything Suddenly Got Worse. And what to do about it. You can find the transcript, the show notes, and the presentation slides over at no script show slash 27. So that's the numbers two seven. And if you're watching this on YouTube, the link will be the first comment just below the subscribe and like buttons.

As always, I'm joined by David Waumsley. Hello David. 

Hello, 

[00:01:26] **David Waumsley:** Nathan Wrigley. Yeah, indeed. Well, last year was I, I think, you know, for somebody who loves the web of quite depressing, I mean, I'd love for this episode first to be talking about all the amazing things that we can now do with the new HTM HTML and CSS that we have.

And now empowering that can be for people who just need small websites, but, uh, we're in a. Bifurcated industry. I don't think I've ever said that word out loud. Oh, it's a good word. I'm, I'm proud of you, David. Ated. Bifurcated. Bifurcated. Um, yeah. Where most creators now, kind of, I was checking this out. Um, 'cause it was just a sense that most people now who are building sort of sites, we do small kind of business sites, that kind of thing.

I mean, I do. You don't so much. Um, I haven't been doing it very long and haven't got that connection with the W three C. And, and that seems to be the case. Most people have, you know, the majority have done it for less than six years and have learned via commercial platforms so. The big thing for last year really was vibe coding, which is, you know, the idea that you don't have to bother with the code at all, you just tell AI what you want and suddenly you've got buy magic this website.

And um, so really what I wanted to do here is to try and get us back to some of the things that our show is about, making websites simply with HT ML and CSS and talk a little bit about what a lot of people have been saying through that year and are as we go forward about the magic that we see with some of this ai, particularly vibe coding.

We probably should be looking for the man behind the curtain, or rather as they would see it as the wealthy techno techno optimists who have accumulated so much wealth that they now probably believe they are actually wizards. So, um, so really what we're gonna do with this is to just, um. Take a critical, uh, sort of use their views to critically analyze where we're at now.

So, mm-hmm. This is gonna turn into a bit of a book review if I go to Alice. No, that's fine. Let me, shall I put the screen on? Shall I share our screen? Yeah, that'd be great. There we go. There we are. There's our topic in stratification, why we need independent websites. That's what we call this. And I'll move on to next screen here, which is really the range of sort of.

Sources that we're gonna use for this to sort of inform this conversation that we're gonna have. Nathan, would you read out some of the, um, books that we're referencing?

[00:03:56] **Nathan Wrigley:** Indeed. I'll just crib directly from the slide. So the first one is Corey, Dr. Os already mentioned and ification why everything suddenly got worse and what to do about it. Then there's, um, a book by Karen Howe called Empire of AI Inside the Reckless Race for Total Domination. Uh, the titles are very sort of incendiary, but also that I feel that they need to be because of the, the nature of where we're at.

Yan, um, Jannis, I don't actually know how to pronounce this person's surname, but I'm gonna give it a go. Varo Farkis is how I'm gonna say that. Brilliant. Um, and it's called Techno Feudalism What Killed Capitalism. And then finally, the book by Sir Tim Burnley. He won't say it, but I will. Um, worldwide Web.

This is for everyone. Beautifully titled book. So four there. And then there's a couple of other resources which aren't books, but something you might want to tune into. The first is, um, a podcast and newsletter by Ed Zitron, who is, um, who's somebody online who's been talking about the financial side of all of this for years.

It's called Better Offline. You can find that@betteroffline.com. And then Carl Brown has a YouTube channel, uh, which you're gonna have to search for, but it's it's youtube.com/internet of Bugs, and that's the name of it. The YouTube channel is simply called Internet of Bugs. There we go. I think I've done that task.

[00:05:22] **David Waumsley:** Yeah. Brilliant. Um, so. Yeah, I should say actually the, the, the books here that we've mentioned, the four books, the authors have done so many interviews. So if you kind of look on YouTube, you'll find plenty. So you don't necessarily need to buy it. And all we can do here, 'cause these are so eloquent anyway, um, that you probably should tune into what they're doing, uh, rather than us.

But what we're doing here is trying to make that a little bit relevant to web design, which is not really their background with this one. And interestingly, I mean these are things that have influenced me, particularly, I've been reading these books on. Partway through a couple of them, but most of all I've read through and they all seem to have a, a similar view on what needs to happen, if you like, for the future of the internet.

And I, I wouldn't say any of 'em necessarily are anti AI in any way. It's just that what I think they share in common is that they believe that the web should be socialized, it should be something that we all publicly own and take part in, like the worldwide web is itself. So yeah. Should I just say, I did make a few notes actually here about the D author if you wanna know.

So I'll just quickly go through them. So interesting we're talking about Word of the Year and ification became the word of the year for the Australian Macquarie Dictionary in 2004, I think in 2003. 'cause he was using the term way before his book came out. Yes, I think you're right. Yeah. Was used, I think some international dialect society or something, picked it as the, so it's a, a word that many of us use and I think it's a really good way of understanding where we're at, at the web.

But he's a Canadian, British author and journalist. You've read a lot of his books, haven't you? 

[00:07:03] **Nathan Wrigley:** I've read. He, he produces novels as well, and that was what first got me into him. Yeah, I don't know, a decade or more ago. But he's, uh, he's extremely eloquent, very knowledgeable, and uh, and, and able to communicate a lot of ideas in a very short space of time because he speaks, he speaks very rapidly actually, and, uh, a lot of things fall out of his mouth in, in the time it would take me merely to think of them.

So it's definitely somebody credible. 

[00:07:27] **David Waumsley:** I know, I think he's given us such a great framework for understanding things, and that's why we call this episode after his title. He says, we can use it for, anybody can use it as long as they're representing what it means in his book, which we'll try and do. Um, but he's also 25 years he is been an advocate for digital rights, for, uh, copyright reform and, and, and really been active in, uh, technology policy.

Um, the other one, the em, uh, the Empire of ai, Karen, how She's somebody, well, you read out the title, which is actually the British title, the uk Oh, that's interesting. I didn't know that. Yeah. Yeah. The, the, the US subtitle is, uh, dreams and Nightmares in Sam Altman's Open ai. And that was published last year as well.

Okay. That's so, yeah. Yeah. I mean, she's somebody who technically knows her stuff, but she's been, uh, covering Chinese tech for the Wall Street Journal. She's a senior AI editor at MIT Technology Review. MIT is how, yeah. MIT. Yeah. Yeah. And, um. Yeah. Uh, her book's great because it gives you a real insight because she's done so many interviews with open AI into the key players, how fragile, if you like, AI is how there's almost, uh, religious fervor fuel in it.

And, uh, she exposes a lot of the kind of half truths that we were told really about it as well. So it's really good. 

[00:08:50] **Nathan Wrigley:** I, I think that religious fervor that you just mentioned is so self-evident. Whether or not you are bullish about AI or have like, shackled yourself to AI and, you know, anchored yourself to it.

You can't deny that there is a lot of that. There is some kind of almost evangelical, um, proclamations out there. It sounds almost like, um, a, a religion in some respects. You know, people are really adopting it and, and not, not necessarily questioning it in the same way that obviously these people are.

[00:09:17] **David Waumsley:** Yeah, exactly. And I've thrown, um, Janni, Fuke in because it is, um, I think his book comes a couple of years before, and really how I think he underpins a lot of this is the fact that he's spotting the fact that we have this techno feudalism, which is killing capitalism, is the fact that somehow we've managed to end up with a situation where all the cloud capital that we have in the world is owned by a few platforms, Google Meta, Amazon, and as such, because we've volunteered into using all these services and become dependent on it, we've become cloud surfs.

So we've kind of gone into this new era and I think that kind of, I'm not really talking about his book in this very much, but uh, I think that kind of underpins where we're at. It's a good way I think, of understanding it. Um, ed Zirin as well, as you've mentioned there, I mean, he's a British tech commentator.

Um, he's a bit sweary, uh, he's, but he's really looking into. Well, he's a critic of growth at all costs and that culture and highlights really the expenses, how much has been paid at the moment for GPUs, how this is inflating everything, but the, it doesn't seem to be solving real world problems. So if you really want to look into the ai, um, boom that we're in at the moment is probably somebody to listen to.

I'm just throwing in Carl Brown on this list, on the slide here because he's one of many, uh, software engineers that's experienced. He's got 35 years experience on this, who is a bit critical of ai, particularly within software development. So, um, that's it. And 

[00:10:56] **Nathan Wrigley:** then No, Tim Burners 

[00:10:57] **David Waumsley:** Lee. Yeah. Yeah. Well finally, because his book came out in September of last year, so it's quite new.

There he is explaining new that. Yeah, he is explained. It's a really good book. Um, the creation of the worldwide web, um, and. I think what I took from it mostly was how easy it can be lost to those same sort of techno optimists if you like. You would like effectively to see a world where democracy's removed, where this kind of tech giants make the decisions in our interests on there.

And just to throw this in, I haven't got a book from him, particularly I I saw, although they don't really mention each other that much. Similarities with Jan Koon, who's one of the three godfathers of AI who left Meta at the end of last year and is working on open source ai. Um. They both seem to have a similar idea, if you like.

I think all of them do about how things need to be in public ownership. So Tim Burnley talks about Wikipedia being the ideal way to sort of share knowledge online. Jan is the same with his. How he thinks that everybody should be pulling their knowledge together rather than doing it in commercial silos.

Right, right. So we, uh, let's move on to the next thing and Nathan, if you'll read that out, let's explain a little bit going back to Cori and, uh, the stages of in notification. 

[00:12:18] **Nathan Wrigley:** Yeah. Okay. So here we go. So, there are three stages, according to Corey, a doctor o of Ification, and they are as follows, number one, re users.

The platform offers a valuable service, which is typically at a loss to attract a massive user base. I think we can all identify that as easy to understand. Number two, lure the businesses or just LEO business once invested, the platform shifts value away from them, the, the users, I guess, towards business customers.

So for example, advertisers and publishers in order to monetize it. And then three, the sort of final stage, uh, extract everything. When business customers are dependent, the platform extracts value from both groups, so both the users and the businesses raising fees and degrading the service. And, um, it's, it's not really in the abstract.

This is it. I think you can chart this across lots of different platforms. This, this sort of three stage approach, it does seem to be a, a playbook. Yeah. I don't know whether it, it started out as an, an intentional thing, but it definitely. Feels like it's a thing. 

[00:13:24] **David Waumsley:** Yeah, I think all of these things just kind of happen.

We just find yourself where we are. We'll, we'll take some of the examples in a minute, but maybe just to sort of go on with that a little bit. I mean, one thing about sort of stage three, if you read CO's book, is that you, you might just see that as being, uh, a benefit to the stakeholders and investors.

You know, that, that, that stage three only they are winning, but also I think, you know, we see that they are becoming the victims as well. So if you take something like Ed Viron, he wrote his longest article ever, which was the and shitty financial crisis where he talks about a lot of the things he's talking about, which is.

How valuations are going on. So how the stock market is being affected by all of this and how they can be, investors can lose out because there's been sort of changing depreciation values of GPU stock, you know, lots of compute power is needed, the buy in everything up, it's raising the prices of this, but they've changed the valuation, how, how it will depreciate to make things look better.

We've had valuations in the stock market growing on the basis of intent rather than contracts. So recently we had Nvidia promising to invest a hundred billion into open ai, but it's just a promise. It's not something that really should raise prices. And there's lots of obviously misleading stories about layoffs due to ai, which actually a lot of people are just using that to break.

Um, workers' rights, if you like, you lay them off because of ai, but you recruit back at a cheaper price from somewhere else, often the case. And there's a lot of circular investments going on, which have been kind of revealed. So the best one is Oracle investing in nvidia, which is invested in open ai and it's going backwards and forwards.

So from his point of view, I think him, both Ed and Cory, if you see them on talks, will say it will take a minor miracle really if open AI is to survive the bubble that they think we are because, and uh, as we notice, we notice that we've got Altman and Zuckerberg at the moment saying that we're in a bubble, sort of talking as if in the third party it's got nothing to do with their kind of theory list search for, um, a GI.

But, um. That seems to be where we're at, but from their point of view, this isn't gonna be possible to bail out anyway, because they were talking about trillions that are gonna be needed and there's no route to profitability at the moment. So 

[00:15:50] **Nathan Wrigley:** yeah, he's, um, ed Tran's definitely doing the rounds. He's appeared on quite a few of the, the sort of podcast that I listen to, and you mm-hmm.

You're right. He, he's quite a sweary, quite a, quite a colorful character. Um, but the underlying message is, um. I guess that he's, he's following the money, isn't he? That's his, his, his take is sort of follow the money and see where that goes. And he's, in his mind, he's extremely sure that the bubble, uh, is not far off collapsing.

I, I don't know exactly what time horizon he's looking at there, but, um, if AI was delivering what it promised to deliver, maybe he'd modify his view. But it's, it's anchored to the fact that he doesn't think it is delivering what it's promising to offer. There's always this distant horizon of, oh, it will do this.

It imagine if we got to this, wouldn't it be great if it did this? And without the investment, it simply can't. And, um, you know, I guess at some point the investment dries up because it doesn't deliver what it 

[00:16:46] **David Waumsley:** possibly deliver. Yeah. I mean, it, it goes to the Y thing where he doesn't believe that this particular way, this language learning machine's neur network approach is the way to get to artificial intelligence.

As everybody understood that, you know. Nobody really understands this. 'cause no one can agree what intelligence is. But effectively, you know, this is a route, but it's a very expensive route to get there. Right. So much has been invested and it's not gonna have, you know, the commercial returns on it because we've seen plenty of reports which haven't listed here, which I think there was one recently towards the end of the year saying 95% of businesses who have invested in it hadn't made any money out of it and Right.

[00:17:24] **Nathan Wrigley:** Okay. And, and then of course there's the whole environmental thing, which you just sort of touched on there with the, um, you know, if, if like me, you believe in climate change and global warming and all of that, the, the last thing we need is more. Um, power hungry computers being switched on, and, and it feels like this is not just, it's not like a few machines were added to the internet.

This is an awful lot. Yeah. Um, I, I heard some descriptions of the size of some of the data centers that are being added to the, the world in order to satisfy the, the power needs of the, you know, the, the expected use of AI in the future. I'm not gonna say what they were, because I'll definitely get it wrong, but they were fairly eye wateringly large, um, data centers which consumed, you know, like city.

Giant city level amounts of power just in this one data center. And, um, yeah, that, that doesn't seem to be aligned particularly with what humans need. 

[00:18:20] **David Waumsley:** No, and it is Ka Howe's focus, I think, with that empire building. And, you know, she picks out the fact that. Um, you know, it's often shell companies will kind of set up these places, data centers, and then it's like, ta-da, we're meta actually, here we are.

And suddenly, you know, people don't have the water or the electricity. They have, they have power outages and stuff like that. So, yeah. Yeah, it's a lot of that going on at the moment. Um, that's to keep with the ification, that's just. Take a few examples. Should 

[00:18:48] **Nathan Wrigley:** we do them one at a time or do you want me to read out all three?

[00:18:51] **David Waumsley:** Yeah, read them all out and I'll just 

[00:18:52] **Nathan Wrigley:** fill in. Okay. So three examples. Um, would be the first one. Facebook, I think everybody knows who that is. Um, attracted users with privacy and friend feeds, then shifted to publishers and now prioritizes boosted posts over organic content. This is such a slow and inexorable thing that it's hard to have noticed it, but I think if you look back, the data would clearly show that this sort of stuff is happening and your feed is no longer what it once was.

Right? Anyway, sorry. Um, Amazon, uh, is the second example. Initially, subsidized goods and shipping. Now search results are dominated by pay to play ads and seller fees can exceed 45% of the sale price. And finally, Google search. Once known for relevant results, it made them worse to increase search time. To show more ads.

Yeah. All of it's a fairly pessimistic picture there, isn't it? 

[00:19:44] **David Waumsley:** Yeah. I mean, this is, you know, taken directly from Cory, Dr. O's stuff, and he also, in his book, he looks into other things like dating apps, the gig economy platforms, uh, Twitter and Uber and others. But, uh, you know, his, he often starts when he talks about it with Facebook because he talks about how really it was real users who turned.

Zuckerberg's tool for rating really college girls, which it started off into a sort of useful social platform. And then when they went after MySpace users, uh, when they got investment on that, they, they largely were warning them not to trust the new billionaire owner, Rupert Murdoch with buying history.

Um, which is a tough sell at the time because people, uh, like to be where their friends are, you know, the other people who are signed up to the same platform. So he offered a way to see their posts via Facebook. Of course, when he became the billionaire spy, he close this down. So operability, you know, interoperability was only a sort of one way street with it.

You can't do the same now for Facebook and have people see your Facebook from another platform. Right, right. Um, so it is, um. There's also, I mean, one of the interesting things I think he mentioned, which I thought in the book was a, a fascinating stat was, was Proctor and Gamble. Um, just to look at stage two, when it's there for those people who want to publish or advertise or whatever on the platform, they stopped their, um, 200 million a year, that's dollars.

Um, Facebook ads and saw zero losses, which I thought was quite interesting. So, oh, that 

[00:21:20] **Nathan Wrigley:** is an interesting stand. Yeah. Yeah, it's a very murky thing. The online advertising systems, well, not just Facebook, but all of them. I, I think it's very hard to understand exactly what the ROI is, but that's, that's an eye watering number, isn't it?

So 200 million just curtailed in investing in Facebook ads. But, um, according to this, zero loss in. 

[00:21:41] **David Waumsley:** Sales. 

[00:21:41] **Nathan Wrigley:** In actual sales, yes. You can't 

[00:21:43] **David Waumsley:** chart it, so it didn't seem to make any difference to their overall business. But I mean, the idea is that everybody's caught up and you have to advertise there because your competitors are there.

That's the kind of trap for most businesses. Yeah. It's a 

[00:21:54] **Nathan Wrigley:** beautiful system for the Facebook shareholders that isn't it? Yeah, absolutely. Capture of everything. Yeah. 

[00:22:00] **David Waumsley:** And Amazon, I think is the, I mean. The, the thing is, we all pay more because of Amazon because when they've shifted to charge more, once they've got dominance and everybody needs to be on their platform to sell the stuff, their deal is that you can't sell it elsewhere cheaper.

Which means that in order to keep paying to be on Amazon, they have to put their prices up everywhere. So whether you use Amazon to get your things, you're going to pay more as these individual businesses have to pay Amazon. So that's the kind of trap that we're caught up in there as, yes. Amazon make it more difficult.

Finally, um, Google search. Well, Nathan, you'll know 'cause you are a CGI user. So CGI is an example that Cori uses as our way of showing how Google's data, which is used by CGI can produce a lot of different results to what Google have decided to show with their algorithm at the moment.

[00:22:54] **Nathan Wrigley:** Yeah, so there's an, there's a, a search engine, which is several years old now, which I decided to give a go, give it a go, and I'm, I'm still using it. Um, I'm paying for it. But that's the difference. You pay a dollar amount a year, um, and you, you do get a very different set of results despite the fact that I, again, I'm not really technically knowledgeable about how that platform, uh, gets its results, but I think Google is in the mix somewhere and, um, they, they definitely look different.

The results that you get, um, you know, you don't get the, the ads for example, that's one of the reasons why you pay. You don't get the sponsored bits. 

[00:23:29] **David Waumsley:** Yeah. 

[00:23:29] **Nathan Wrigley:** Um, and you can modify the, the search in, in a way that you kind of prioritize your own things. So you, you might, for example, want news to come from this particular website and you can sort of favor that.

So you can wait it in your own way if you like. So, yeah. Yeah, yeah. Definitely different. 

[00:23:44] **David Waumsley:** And I think, yeah, um, Curry, Dr. O makes the point about Google, uh, something, which I think we felt ourselves with that one 'cause it's one of the few, if you like, meta Meta Corps out there that I think used to promote free academic thought.

You know, it started that way. You've got Larry Page and you've got Sergei Brynn who were the students who came up with page rank, which told us how we could organize the web search for it. I mean, it was brilliant science, if you like, at the time. But, and they've always had that tradition of introducing, um, academics who will come in.

But this seemed to change quite considerably when ai, when they needed to, when they'd reached a level of sort of 90%, um. Use of Google, where do you go from there? So, you know, AI becomes the next big thing that they want to put it in. So when people are critical of ai, they're the people who have been having to leave Google or sack from it or leave themselves.

So there's a big change in what you can say now 'cause they need to raise funds there. Um, so a lot of people, yeah, I mean Cory, Dr. Row says, you know, when he is presenting this, or I'll say the same thing that, um, and certification may sound like it's just good old fashioned capitalism, but really it's anti-capitalism in a way.

And I'll move on to the next slide. 

[00:25:04] **Nathan Wrigley:** Okay. This has got a great title. Um, let me make sure I get this right. The inverse. Um, so three strands to this. The, the first one is removing or removes interoperability. We can get into that and what that means. Uh, weakened antitrust regulation. And uh, it also reduces.

Worker power. Okay, let's prize this one open. 'cause there's a lot in here. Yeah. 

[00:25:29] **David Waumsley:** Yeah, so I mean the examples of removing interoperability, one I already mentioned anyway with Facebook, you know, locking your data in, which of course, you know, because of the fact that MySpace didn't allowed them to compete with them.

You can't really do that in reverse now. So that's one example of it. But there's generally, and it often starts, a lot of talks about this one, uh, he mentions a lot one piece of legislation that's in there, which is section. 1201 of the Digital Millennium Copyright Act, and apparently this law, which is also known as the anti circumvention role, makes it a felony to bypass any digital locks.

So when you've got chips in things a. That's a way of being able to say, ah, you can't bypass this and this is how it can lock people in. So you remove this interoperability. And the example that is often used is with printers, how you can't go and buy your ink from a third party, whoever's given you the cheapest, you have to buy it from the printer that you've got because they've got that sort of legal right because you, they've got that chip in and you can't bypass it.

[00:26:33] **Nathan Wrigley:** Right. And the, the printer ink costs more than, I dunno, crazy statistic. Like it's more expensive than platinum or something like that. 

[00:26:40] **David Waumsley:** Yeah, yeah, yeah. Absolutely. And, and there's so many examples of this one, the most recent one I heard, which isn't in his book, which is about smart TVs. I mean, they're being sold at a loss now because we're paying for them to install something which spies on us and gives us the adverts that we want.

And everything's gone smart. We've got smart beds, we've got smart everything. So you know it, it's using this kind of law, if you like, to be able to stop that in. Interoperability, which is a key thing to being able to sort of share our technology and move things around as we like. 

[00:27:10] **Nathan Wrigley:** Mm-hmm. 

[00:27:11] **David Waumsley:** So, I mean, it makes the point as well, you know, that, and again, this is something related to the web that most companies would rather that use their app rather than the website.

'cause they can bypass some of their GDPR laws much easier. It makes it easier for them to spy. And as a great example he gives is of Uber who, and there's a lot of talk about this in not just them, but they will use an app. So if somebody's calling for a ride and they see that their battery is low on their device, they may up their price because they know they'll be desperate to get.

That ride quickly. And if a driver, um, is too quick to respond to lifts or has a certain pattern that shows that they might be a bit more desperate for the money, they're likely to get paid less for it. So there's a lot of price fixing that can be done via apps. Yeah, 

[00:27:58] **Nathan Wrigley:** I heard that. I, I didn't hear the first story about the, the low battery, but that, that is really interesting.

But I did hear the second one. I can't remember where I read it, but that as I was reading it, I was just thinking, God, it, it's like evil genius territory, isn't it? You're sort of, you know, stroking your little cat. Yeah. On your big, big chair in your evil underground layer. It's just remarkable. You know, the idea that if, as a driver of the service of, and again, ca caveats around this, we're saying what we heard, um, yeah.

You would as a driver. You would be penalized because you are good at using the Uber service to get more rides. They see you as somebody that's, you know, just like desperate. Well, we can pay you less if you're desperate. That's just so I know. Again, not in, 

[00:28:42] **David Waumsley:** not in his book. I've seen some other reports where people are looking into, um, some of the, the shopping delivery things and how they will charge you differently for different customers.

They've been testing this by using different apps depending on their spending behavior that will price up the items that are in the shop that they're bringing to you. Really, really interesting stuff. 

[00:29:01] **Nathan Wrigley:** It's such an interesting psychology though that, that everybody is like a commodity. It's like you are something, yes, you are like the sack of money, um, and whatever the conditions are that allow us to get more of our hand into your sack of money and pull out more a any condition that we can use to make our hand bigger and your sack more wide open.

You'll use those, whether that's the battery on your phone or the, the desperation, um, of you as an Uber driver. You just sort of prize, open all these things and try to maximize it. It's so. Peculiar a way of thinking about just life and relations and everything in general. It's such an, oh, I have no words.

It's so strange. 

[00:29:48] **David Waumsley:** Yeah. Antitrust. I mean, uh, obviously that's stopping monopolies. If we want capitalism, we realize that it does have some downsides, so we need, you know, to regulate against those. And Cory makes the point that really these have weakened really since Nixon and only started to tighten up a little bit under Biden, which was a surprise to me.

But I think that the example that he uses is diapers.com when, um, you know, we'll come out of the, the bubble, uh, of the.com bubble. Um. This was aggressively bought by Amazon, uh, because they just had the money to be able to out, you know, at loss. They would sell the same stuff until they basically folded.

So it was a kind of warning, if you like, an early warning to everybody that wants these mega corps that got to a certain size, you sold to them. You know, I'm gonna, 

[00:30:36] **Nathan Wrigley:** I'm gonna dwell on this a little bit 'cause I remember reading that in the book. 'cause I think it's really interesting how that. Story unfolded.

So the, the story that Corey tells is that Amazon want, if I get any of this wrong, just correct me, they wanted to buy diapers.com. Mm-hmm. diapers.com didn't wish to be sold because they thought that they had a, a thriving business. So they were selling what we call in the UK nappies, but diapers everywhere else.

Mm-hmm. And, um, and so Amazon said, we'd like to buy you. They said no. And so Amazon's tactic was to sell the, an equivalent range of products at a remarkably reduced rate because they could obviously, you know, just consume that loss over and over and over again, thereby driving the business of diapers.com out just it, you know, it vanished.

They then bought divers.com a rate, which was significantly less than they would have done previously. And, uh, and, and then presumably, I don't know if this is the tail end of that story, then presumably raise the prices again. Um, yeah, 

[00:31:36] **David Waumsley:** exactly. Exactly. Yeah. Oh, I, I mean, we've seen, I've, you know, friends of mine, I think I told you about this before, I had the same happening with Starbucks.

They had a cafe, Starbucks turned up. They offered free coffees, trying to put them outta business, that they actually were, they moved on eventually. So. Gosh, the one out the public decided they knew what they were doing. It was too obvious. But, um, yeah, same sort of thing. So, I mean, it was a sort of warning and I mean, he makes a point in his book as well about most of the Google inventions that we see, um, were bought, you know, they, they few, you know, were there.

So that's kind of the way we're going. And, and, and it's no surprise I think to me that we have the sort of techno optimist like Mark and Andreasen, who has a kind of hotline to Trump, really always is Trump's person to be able to communicate what's going on in, uh, Silicon Valley. It's no surprise that Trump wants a sort of 10 year ban on state and local AI regulations on this.

They wanna sort of free that up. So, you know, antitrust is being weakened there. Although Cori sees though is, uh, an opportunity, there's a sort of growth in it as well. At the same time, you know, we've got more antitrust, um. Action's being taken against the big corporations at the moment against Google, against Facebook.

So there is something changing there. Um, let me just finish off the notes I got here as well. Okay. Which is just about the reduced worker power. I mean, Cory again touches on Apple using Foxcon in China there where they needed suicide nets for the treatment of their employers there. So that's how you get your cheap Apple stuff.

It's at the cost of some poor Chinese workers. And there was a wonderful documentary, if you can find it on YouTube, it's well worth watching 'cause it's hysterical. Um, UBA Butler, um, is a sort of prankster and journalist who got into Amazon as a worker there. He spotted that Amazon drivers were, because there was such a tight schedule, were having to urinate into bottles.

So he managed to take some of these bottles, package it up and make it into a bestseller on Amazon.

You can't beat that. Um, yeah, I mean obviously he didn't sell it to real public, public, it was his own friends he was selling to, just to make the point. But within that, he realized that the place where he got a job, they were just recruiting loads and loads of people. That's why he got in, because they were trying to break the attempts to create a union there.

Uh, and they have to get over 50%. So as soon as you get close to getting 50% of your workers will join a union. They can fix this by employing lots more people to make sure you can't have a union. So, oh my gosh. Yeah. So that's the kind of things there. So, um, yeah. Um. There's a lot more in Karen. How's book though on the other side of AI as well?

I mean, her concentration is on really what it's doing to the environment, but also about how the magic of AI isn't quite the magic. It relies on a massive amount of hidden low page human labor. So in terms of if they just left all the stuff that is scraped to go out there. It, uh, it wouldn't be something we'd use, it would send out all sorts of stuff so they get low paid workers working for like a dollar a day or something to be going through the most awful content that you can find on the web, sexual and violent content and stuff like that.

So they're getting all kinds of mental health problems with that one. So, so we definitely, uh, kind of see that going on. Can I move on? Sorry. Did you want 

[00:35:08] **Nathan Wrigley:** No, no, no. Uh, it's just you have to take a breath, don't you, and sort of think about all this for a bit. And I mean, we all know that humans have the capacity to, to do Yeah.

Interesting things to one another. Let's just put it that way. And it all sounds so almost like a dystopian. Novel. Yeah. Some kind of version of the future in some science fiction book, but, um, we, I think it's, you know, we, we know that humans have the capacity to, to do things in the pursuit of profit and, um, disregarding all sorts of things that you probably wouldn't wish to happen to yourself and your family.

It's very easy to disregard those exact same things because it will turn a profit for you. And your accompany and keep food coming onto the table and so on. And, uh, yeah, we're, we're a curious species, let's put it that way. 

[00:35:57] **David Waumsley:** Yeah. So when we're using chap GBT, we don't realize that, you know, the, these Kenyan workers who have made this ex, you know, uh, a a dollar a day who are making this and.

You know, seem very human and nice to us. So something to bear in mind. But anyway, talking to the magic of AI on this, shall we move on to the sort of vibe coding hype of 2000? Okay. Nice segue. 

[00:36:17] **Nathan Wrigley:** Okay. And, uh, the colors of the slides change. Woo. So here we go. Um, so vibe coding hype of 2025. Um, I don't think we need to describe what vibe coding is, but I'll do it anyway.

Vibe coding. The idea that I, it's such an unusual word. I don't even know how like vibe coding became the word, but it did. Um, in February in 2025, the term was coined by, I'm gonna say Andre Cari. Um, forgive me, Andre paid. 

[00:36:45] **David Waumsley:** Yeah. 

[00:36:46] **Nathan Wrigley:** Yeah. Thank you. Uh, who was one of the co-founders of OpenAI. Uh, it was a viral post on x formerly Twitter, uh, vibe coding became the term.

And then in March, the phrase spread so rapidly. That it was added again to the Miriam Webster dictionary. The Miriam Webster dictionary has had an, an unusually large presence in this, this particular epi particular episode. Um, it was put in there as a slang and trending term. I think it's fair to say. It appears everywhere on the internet nowadays.

Uh, and then by July, the startup accelerator Y Combinator noted that 25% of its winter batch was building. So, Y Combinator is a kind of organization that you can get involved in if you've got a thing that you want to launch into the market and, you know, you wanna prove that it's got legs, um, and you want funding for it.

So 25% of its winter batch was building companies with code bases that were 95%, uh, generated by ai. That's quite a statistic. And then towards the end of the year, September, major tech outlets began reporting a vibe, coding hangover. A senior engineers struggled to maintain the brittle. Code bases. Okay.

Give us more, David. Yeah. 

[00:37:57] **David Waumsley:** Yeah. I really followed this hype. It was depressing to me. I mean, it was fueled, there was books, there was, by the summer, there was books, courses, and then also the tools that were coming out. So we had Cursor, which, uh, Andre, Ty was talking about actually Cursor when he was doing it, and he was saying, you know, you could just go with the vibe with this.

I can let it do all the work. That's where Q came out of. There was rep agent, there was lovable, there was Bolt. People were talking about that. You just type it all in and just go and it'll send out what you want. And, uh, you know, I think the interesting thing is we look at these, um, and I don't see this talked about, this isn't in Cory's book or anything, but, uh, I, I looked at, I for myself, all of those companies, they have good revenues at the moment, people are interested in, but only Repli, which was only recently pivoted to AI.

First. It used to be a good sort of. Develop a training tool before shows a profit. And if you listen to the users of rep, there's some real horror stories about it. Completely deleting, um, databases doing its own thing with the AI ruining all the work that's gone before. So it is quite interesting to look at this.

And I think also if we're thinking about the certification side of it, you could say they're kind of the stage. Two people, the businesses coming in to make money out as the ai, but they're all paying high fees to the foundational AI providers like Google, Nvidia, open ai. 

[00:39:19] **Nathan Wrigley:** Yeah. 

[00:39:19] **David Waumsley:** Whilst at the same time trying to compete with those same tools.

So, you know, you wonder whether they're going to escape stage two and certification. I mean, are they, it was also 

[00:39:29] **Nathan Wrigley:** kind of interesting how much of a sort of hype cycle they, they they're in, because some of those tools were kind of everywhere in my feed. You know, people were talking about 'em all the time.

And then quite a lot of them sort of seemed to disappear off the radar of popularity that maybe I, it's just that, you know, they were no longer, it's no longer worth talking about 'em 'cause it's no longer new and the use continues. So they're very, you know, they might still be successful, but there was a lot of, lot of hype and buzz around what they could do and, uh, how point, you know, basically you just write a sentence and dah dah, everything's working.

But, uh, yeah. Anyway, so I dunno if that remains to be true, whether or not they've got. Users still sounds like one of them at least, is is still credible rep, the one that you mentioned. 

[00:40:10] **David Waumsley:** Well, still sort of profitable. I profitable, that's the word I meant. Yeah. Thank you. Yeah, so that, I mean, they're all doing, they're all there and people are still using them.

I, we'll move on to this one, but I mean, what I found interesting at the time was I was listening. I mean, I'm not a developer myself who's into, you know, proper software development, but pretty much all of 'em, all the big players you'll see on YouTube, all thought this is all just very stupid because it doesn't, doesn't follow anything that they know about development.

So, because l LMS are a probability machine, so it's like. You know, this is Ed Trons term. It's like pulling the arm of a slot machine every time it'll turn out something different. So there's no way of being able to work in an agile way and have version control. So you know what you are building on. You should start simple and keep building up.

So it's really interesting. And there was some reports, um, Git Clear, uh, does a comprehensive analysis of it says 211 million lines of code, which come out of Git. And over this time they've seen this sort of eightfold increase in duplicate lines. So there's less global management, less, uh, dry as used.

Don't repeat yourself in code basis and code churn doubles because you're just constantly, if you're using this, you are just making new code each time. So there's no way of being able to do what developers have always needed to do. You know, they start with. The most simplest thing and build up and with a process, but if you use that, so, um, should we look at what Vibe coders are saying at the moment?

[00:41:42] **Nathan Wrigley:** Indeed. Indeed. Okay. Yeah. Okay. So Vibe Coding in 2026. Um, so again, back to this chap, uh, Andre Carpe, the, or Carpathy, I'm not sure. Uh, built nano chat by hand, uh, stating AI tools weren't helpful for that. Then Boris Cherney, who created Anthropics Claude Code acknowledge vibe coding works well for throwaway code and prototypes, uh, but fails when developers need maintainable code.

And then Michelle Trull, who's the CEO of Cursor told Fortune's Brainstorm AI conference, that vibe coding may work for quick prototypes, but creates unstable foundations. For serious applications. Thi this is some, somewhere I sort of arrived at independently of any of these three characters and it just felt that really, maybe if it's something on your local machine where you had a use for it and it was disposable.

And I use the example of, I dunno, let's say you're about to file your tax and all of the bits and pieces that you've got lying around on your desktop and what have you is, is difficult for you to pause. Maybe you'd get something, it would do that work on your computer and then after you've submitted your tax return, you just mothball it, dispose of that thing.

But, but it's not out there in the wider world to be used by anybody. It's just you and you. You take the consequences of, of whether or not that spits out nonsense for you. But it's a personal project which kind of gets thrown away at the end. That seems to be where I was getting in the latter part, 20, 25.

Sorry, over to you. 

[00:43:13] **David Waumsley:** Yeah, no, I think you're right. And I, I feel that's how, 'cause the ones that I saw, because of the type of crowd that we have to sort of people more do it yourself websites or building small websites. I saw Canva as being the big thing. It was all ai. You could build everything. But I see following.

The backlash you got from Figma when they tried to do that same where you could turn your designs into code with that one, it got such a slate in. I see. That canvas seemed to be talking more in the terms that you are talking about. These are nice little applications for your own use, you know, a little calculator or whatever.

But, but there is, I think there's a split in now if you, you hear people talking about good and bad vibe coding rather than abandon the whole idea. Okay. Um, so you've got, it's good in the hands of coders who actually know how LLMs work and know that they're not going to be accurate all the time. So you make it into small little chunks that you decide what goes into the code base.

That's one use of it. Good for the personal lapse that you are talking about, but bad for. The non coder who have live public facing websites that they're gonna put out because they're gonna be insecure and also they're going to be locked in, aren't they? To that? If they want to change it, they rewrite the whole of their page again, they have no control of it, and suddenly they are serfs because they are something that they could have probably done with HTML and CSS on their own.

Quite simply, is now something which you have to rely on, the AI and whoever's providing it to keep control of it. And, you know, it's dangerous, isn't it, really? If you, if you put something up that has insecurities that you wouldn't normally have, because a lot of these, these sites are using technologies that you wouldn't need to have.

If you HTML CSS, that's fine. But most of these are churning out things with lots of JavaScripts and lots of, you know, really complex stuff. 

[00:44:59] **Nathan Wrigley:** So, Hmm. It's very interesting, isn't it? 

[00:45:03] **David Waumsley:** Yeah. Sorry. We'll move on to something more positive. I mean, it's interesting. I think that, you know, most of the major technology companies, Amazon, Microsoft, Google, meta, Tesla, they've all gone in cycles of laying off developers only to rehire them again at a lower rate.

I mean, they use AI as the reason, because that boosts the idea that AI is important. But they, they get people back because it's not that important. But also they get them back at a lower rate, you know? So, so you're breaking the workforce again. And that's kind of the thing. So, you know, maybe the devs, um, Cory's, you know, he's quite amusing on these sort of things.

So he says, you know, he's always telling devs to watch out. You know, they, they can't yet treat you like Amazon workers or someone is working in a Chinese company for a, uh, for Apple or something. But, you know. They really don't want you to have these wonderful sort of offices where you've got fuse ball and cappuccinos on demand.

Right. The old Google 

[00:46:01] **Nathan Wrigley:** offices that everybody was, you know Yeah. Exactly. Wasn't working at, yeah, yeah, yeah. You 

[00:46:06] **David Waumsley:** mean with your pink mahoan and you can have tattoos, you can have, you know, whatever piercings that you like, you know, at some point, you know, if they can get rid of you with AI, then you know, that's what's gonna happen.

But, ah, y yay. Anyway, so right next I think we'll finish off with a bit more depressing stuff there. Oh, great. Before we get Lovely. Yeah, yeah, yeah. Just to end it, um, we'll finish off just with the sort of socioeconomic perspective of, you know, this kind of authors that we've been featuring. 

[00:46:36] **Nathan Wrigley:** So this one then is entitled, what's Fueling the AI Hype?

Um, so three points here. Monopolist easy for me to say. Uh, monopolistic tech companies need, uh, fresh growth stories to satisfy customers. Um, then this one, which is much broader imperial expansion using a GI as a quasi religion. That's kind of interesting. And then the final one here, consolidating power by undermining democracy, right?

This is, you're really opening the, uh, opening the jaws of this conversation, getting on a global, uh, civilizational, uh, level. Let's, uh, let's see what you got. Yeah, 

[00:47:16] **David Waumsley:** well I think this is what all the authors are kind of looking at in a way. So Dr. Ro and Ttra are really pointing out the problems, sort of mentioned it anyway, the problems of growth when you've already got a monopoly.

When you are, you know, you, your Google search, you've already got 90% of your people you need to find the best thing and the, the, the latest thing quickly. And ai, anything that looks really good with AI needed to be that thing. So there was this kind of need for growth there. You need something for investors.

You need to tell 'em you are there at the forefront. 'cause they need more money, we need more growth, you 

[00:47:46] **Nathan Wrigley:** know, um, growth is always the thing. David, you have to be growing. There's no, yeah, there's no point in existing unless you're growing. 

[00:47:54] **David Waumsley:** And, uh, the, I mean, it's about imperial expansion because, you know, the tech and governments are kind of into it.

Twined these days really for this, you know, that they're both financing each other in some sort of way. But I think Karen Howe is the one, I mean, she points out, particularly with Sam Altman, how he had diverse investments. I mean, most of these people are, you know, they're not inventors, they are investors and they look for new business opportunities.

Sam Altman had, um, you know, lots and lots of 'em at the time. He jumped on this and she, she quotes really at the beginning of her book, something that was in a post by him in 2013 where he was saying about the most successful founders do not set out to create companies. They on a mission to create something closer to a religion.

And that's very much the way that open AI have gone about this whole thing. Interesting. Yeah. So I think, you know, most of 'em will be pointing to the fact that we have those techno optimists. We have Elon Musk and Dr. Uh, mark and Andreas and Peter Thiel. Panier, um, Palantir. Sorry, Palantier, 

[00:48:56] **Nathan Wrigley:** that's right, yeah.

[00:48:57] **David Waumsley:** Was tripping over my Wednesday. Um, you know, who generally as a view they see. Democracy as a problem to progress. You know, it really needs to be in the handful of geniuses who will be able to do this. And this is why we're there is this sort of consolidating of this power, trying to make sure that it's only led by a few people.

If everybody's doing it, then it just ends up with a mess. So that's kind of, um, where we're at at the moment. It is interesting though, I mean, Karen, how makes the point about Sam Altman where you, you never know where somebody like him stands on everything. 'cause he's got the, the, uh, he does what his home product does, which is kind of mirror what you want to kind of hear all the time.

So he is good at raising investor money, but if you are somebody who, with artificial general intelligence, you believe you are a, a dor as Karen calls 'em, somebody who thinks that it's gonna. Killers all in the end, or you are a boomer that is going to, you know, we're all going to live in abundance forevermore.

It, it just really depends who you're talked to because as far as, as far as this whole project's concerned, Sam is both of those, but. Both talking about this is, is really good for the hype and I don't think, yes. Yeah, 

[00:50:11] **Nathan Wrigley:** yeah, yeah. That's an interesting point. Anyway, sorry, go on. 

[00:50:14] **David Waumsley:** Yeah, no, it's fine. Um, what, um, there was just some other points here to make, I mean, there's so much we could talk about this, but I probably should skip on actually and we should talk about, um, the very obvious exception to.

Kind of what we've been talking about there is the worldwide web itself. 

[00:50:32] **Nathan Wrigley:** Okay. So the strap line here is beautifully encapsulated. The web is for everyone, which is a lovely sentiment. So Tim Burnley, the inventor of the worldwide web published, this is for Everyone in late 2025. That's the book that we showed on one of the first slides.

Um, it's a modest account of how this invention was built on the work of others, but it's also an account of the struggle to keep it in in public ownership. Um, it is critical of unregulated algorithm controlled. So you sort of summarized the, the book in just four bullet bullet points. Yeah. Was there, yeah.

Was there more that you wanted to flash out on that? 

[00:51:12] **David Waumsley:** Yeah, just a little bit. I mean, I suppose what, what it was is that, um, it is quite modest in the fact that mostly what you did is the add, the HTTP protocol really making us be able to connect for one computer to another without the logins. Things like link and basic HTML style tags, which we used today, which were obviously fleshed out what already there in place.

So, you know, he is good at acknowledging that shared resources. This kind of openness about your technology is there. Um, I mean he just made it obviously considerably more powerful for me. I would like to say. I think he deserves all the accolades that is, he's. Been given really for his ability to be able to keep the web in public ownership.

Mm-hmm. So we have something like the W three C that makes all of these big powers have to work together. It doesn't progress. It's slow, but it doesn't progress until everybody agrees and everybody's on the same side. And it's one is few examples and I think that's why, uh, it's so great because, I mean, just recount a few little details and I think they're worth just sharing here.

I mean, obviously in the early days there was Mark and Andrea and, uh, with the mosaic. Um, browser and he very much, I mean from Sir Tim's point of view, it was very much he could see that, uh, he, he liked to take credit for the web, take credit for the mosaic against his sort of partner. And he very much was keen to set up, uh, uh, sort of conference, if you like, to bring everybody together really around his vision.

It's only that. So Tim managed to get something together, which turned into the W three C ahead of him. Otherwise, I think it would be slightly different. It would be a little bit like open AI not being ai. And he also makes a point, I'll tell this story anyway. He talks about, uh, Google's. Ian Hixon, who was the chair of the HTML development group around the time of HTML five, and he, um, managed to create a sort of splinter group taking in Mozilla opera and Apple away from the W three C at that point, um, to create the WA work.

I never know how to say that, but it's the web hypertext application technology working group. Yeah. Obvious wish I would come up with short names for these. Um, but you know, from his point of view, he said he seemed to have a problem with accessibility reviews, you know, that he had to do for this one, and it was very, you know, good at being able to pull people away.

So there was a break off from the WCC at that point on it. I mean, what. White was foiled eventually is because they discovered posts on his belief in human, uh, humanitarian eugenics. He believed that mothers should have a license to be able to have children and everything. So the, the tide turned against him.

But what was revealed later is that the reason this splinter group was there, because he was working for Google, seen as someone neutral at the time before they had Chrome. But what was discovered there was that, you know, Google was secretly working on Chrome at the time, so it would favor them to splinter off on the W three C.

So yes, it makes a just a, just a small thing. Yeah, it's quite interesting. So I think the book, from that point of view, you just have to say. You know, inventing is one thing, you know, but he's done that with the help of other people there. He's put the, he's joined the dots together. That's why he's so keen on this kind of open stuff and everybody being brought together across the world.

And I think, you know, that's the, the key thing with that, where people want to kind of take this away really, if they can. So he is managed to keep that going. And I think it's really successful at the moment. At the moment we've got why we've got this show is because of the fact finally the browser walls are over and we've got this interoperability that's running at the moment, allowing HT ML and CSS to really advance quickly.

So I think, you 

[00:55:01] **Nathan Wrigley:** know, 

[00:55:02] **David Waumsley:** you know, without that, it would've been lost on that. Um, he does make the point, and I'll go in about the, I think one of the key things he wanted to make was the, the fact about these addictive algorithms that they're legally allowed. That you can, you know, w. People like Facebook and uh, TikTok or whatever, they know what's addictive on this.

They know that. What gets us angry into this, he talks about Cambridge Analytica and how that had an impact on Brexit and Trump's campaign in the first place. And as you mentioned in the beginning about Australia's social media ban for the under 16 year olds, he, you know, he points out that something that I felt as well, but it's nice to see that he felt the same, was that it's just not getting to the root cause.

The root cause is somebody needs to do something about harmful algorithms. 

[00:55:51] **Nathan Wrigley:** Yes. It's kind of, um, trying to put a, I don't know, a visor over, you know, a a blackout blind over somebody's eyes. Um, and yet it's still there in the background doing Its doing its interesting things. Yeah. Yeah. Okay. 

[00:56:04] **David Waumsley:** Yeah, I'm a, I'm a victim of it and I'm, you know, what's 60, 60 something now, so, yeah.

Yeah. 

[00:56:10] **Nathan Wrigley:** You only have to look along, uh, any row of any human being, uh, in, in this era, uh, to see the, uh, the addiction to the phones and the, uh, the social media. It's pretty rampant everywhere, isn't it? And I guess the systemic root cause is because the algorithms are incredibly successful. They're jolly good at doing what they're doing.

Um, yeah. Making us feel angry. Yeah. Yeah. And, and engaged, you know, just like, or maybe engaged is the wrong word, but it captures our attention very successfully. You know? Incredibly successfully. Yeah. Um, okay. Right. So, and just, 

[00:56:46] **David Waumsley:** just finally with him, I should mm-hmm. Just mention the things that he's doing.

'cause I think they're quite interesting. So he has a, a company, anyway, interrupt. Um, and they've, he, he, he doesn't get much publicity really for those kind of things that he wants to talk about, but his idea for Web3 0.0 if you like, so apps and Facebook and all of that stuff. The social media was, if you like, 2.0.

What he would like to see is that data goes into our own ownership. So he has the idea of these agent wallets and he has two sort of products, which is going out, which has been used commercially, but isn't out for us all at the moment. Which of course will be all open source stuff, uh, solid. And Charlie, so solid is, uh, a way that we can store our own data where we want, wherever we want.

We might choose to use it on, you know, with Google some of it and we can disperse it. And Charlie is this sort of AI that he's working on that will kind of allow you to take the information from the web and then align it with how your life is to remind you how you've done your work. So it's a very different route around it.

Interesting. 

[00:57:52] **Nathan Wrigley:** Okay. Yeah, I guess we'll put links to those into the, uh, description below the, yeah, below the video or the audio. Okay, great. Yep. And, and then we'll one 

[00:58:01] **David Waumsley:** last couple. 

[00:58:01] **Nathan Wrigley:** Um, 

[00:58:02] **David Waumsley:** yeah, we're our reclaiming agency, so 

[00:58:04] **Nathan Wrigley:** Okay. So more or less the penultimate slide. We've got reclaiming agency. So three points here. The worldwide web is low tech. Uh, there's no need for a third party platform to make an effective website. All true. Um, the second point, we can own our own data and syndicate elsewhere.

Again, all true, albeit not at the minute, but it'd be nice if we could spin it that way. And the final one, we can build for people rather than algorithms. That, personally, from my point of view, that's the, uh, that's the crucial one. That's the one that I think needs to be in everybody's mind when we're thinking about this.

Yeah. Yeah. 

[00:58:40] **David Waumsley:** I mean, I've been thinking a lot about why they. Why I sort of feel no energy about websites and used to be so excited about it in the early days. I think the early days it represented this way of cutting out the middleman, being able to do things for our own, didn't matter what they were, whether they're capitalist ventures, whether they were socialists.

You could cut out and, and be your own person and put something out, connect with people across the web. But, and it felt very empowering in the first place. Yeah. Now it seems to have got really stodgy, but I don't think it has to be the same web is there and it's got so much better Just recently since interoperability has finally been achieved, you know, with the browsers.

So I think, you know, it'll take a bit of time, but if we're willing to give up, um, you know, sort of this need to go for short-term conveniences and stop falling for the marketing, you know, we can start making websites. Um. That, that you know, that it's so much easier. And that's what our kind of show is really about.

It's about making some of the new hasty l and CSS, which is kind of vibe coding, just kind of took over. Nobody was really talking unless you were a developer. You weren't talking about how great CSS has become and how Right. Much more you can do in, so that's really the reason for this one. So, I mean, we can't, as people do much about things that I, you know, I hate the fact that we seem to be creating lots of fake enemies to fear around the world all the time.

The fact that we've got wealth inequality, which is getting worse. The fact that, you know, NHS data in the UK is just being shipped off as every other bit of data is to a few US companies. But we can avoid spending a fortune on a website and not have to continue to pay to promote it and update it. So if you, if you spend a lot on a website, which is on a platform, you have to maintain it.

If you. Then spend that money, then you are almost, you have to get your visitors back on that. So then you're on with your Facebook and your Google ads. In order to do it, it's kind of like a trap, but we could go with the dumb web first and follow the rule of lease power like most professionals do, and just start with what we need, which in most cases for the sites most of us build, all we need is the htm, LCSS.

And maybe we'll just need an open source, um, generator like, uh, eleventy, which we're using if it needs to do a lot or, uh, WordPress or something like that to be able to create our stuff without getting locked into. All kinds of systems. So we talked about it before, didn't we? On the show, we did something on the indie web and they got that position where you publish that, that posse thing where publish your own site, syndicate everywhere else, and they talk about web mentions and all of that kind of stuff.

So it's just something that we could be jumping on. Yeah. And, um, anything you wanted to say here before we get to the final? No, I, I 

[01:01:38] **Nathan Wrigley:** mean, apart from the fact that it's just, it's just a lovely alignment of where we, we would like, well, you and I would like the, the arrow to be pointing in the year 2026. I mean, you've laid out the case there.

You've done obviously a lot of research for this episode, for which I'm very grateful. Thank you. Lots of show notes that you can't see, by the way, dear listener. Um, and you've painted a, a, a, a picture of well. Some, some sort of dismaying version of how we are in the beginning of 2026. And then right at the end, here's some solutions there.

There's this, there's this technology that exists. It's free, it's open, it's available for everybody. And somehow we've, we've been wearing blinkers for the last decade or more, and we've been all kind of co-opted, um, voluntarily. Let's go with that. We've kind of, mm-hmm. Maybe walked into things without really realizing what was going to happen again, maybe it wasn't intentional.

Maybe it's just the forces that work that slowly over time get us to where we are. Where, you know, this ification that Corey Ero talks about, maybe it wasn't intentional, but it certainly happened. But there is a, there is a little bit of light at the end of the tunnel and it's, it's free, it's open, it's available, and it won't stop you doing anything.

Um, but maybe we just have to realign and realize. What we're doing. Yeah. Before it's too late. Yeah. 

[01:03:00] **David Waumsley:** Yeah. I think it's just a case of like ai, I mean, I think AI is wonderful. You can use it in your own way. As long as you have control over it, it's not going to take away your agency and give that to a small number of companies to Yeah.

You know, then have control. And I think that's it. So, and last slide here. Um, 

[01:03:17] **Nathan Wrigley:** yep. The last slide is, uh, is it the end or the start? Do we have to record this all again? Um, so this show, the aim is all about building websites that counter slop with quality. Ification with ownership, feudalism, with federation, ai, empires with human ingenuity, empathy, and respect.

Did you write those four PO points or were they some out of the mind or somebody else? 

[01:03:43] **David Waumsley:** No, they're, they're, they're mine. 

[01:03:45] **Nathan Wrigley:** I love those. They more or less encapsulate it perfectly, don't they? It's very pithy and gets to the heart of it all perfectly. I love that. Really nicely gone. Ah, 

[01:03:53] **David Waumsley:** okay. And I, I, I kind of felt that we're going into a new year and we've been doing a show, not kind of moving into it, not knowing what we're doing, but in some ways, I, I think the show should have been called The Dumb Web Show.

Actually. You can have certainly based 

[01:04:07] **Nathan Wrigley:** upon me, it should be called 

[01:04:08] **David Waumsley:** No, no, no. But I mean, you know, dumbing down the web because you could do so much more with simple technologies, uh, without having to make it so, you know, like you're trapped into the new thing all the time. You have to jump on for what we do.

Make small websites where we can connect with people still, I mean. Nobody knows. You don't need to spend a lot of money on SEO 'cause nobody knows if the AI is going to be the way with it. But if you put yourself out there and you do it and you keep the cost low, you're going to reach other people, you know?

Mm-hmm. And you can still use the resources there. So I think, you know, it's our, I, I wanted to do this one because it's kind of our mission, I suppose, for the show, because what we'll try and do throughout this year is, we'll, we did it before, we tried to make some websites, but we kind of skipped over it.

And we're still learning, uh, you know, CSS and stuff and some of the complex stuff. What we'll try and do this time is to. Show the simple process how anybody really people with no prior coding knowledge can simply make their own simple, say business websites or something for local business. And I think we'll try and do some episodes where, break that down into very, very simple thing so it won't be sort of highfaluting, uh, academic stuff for that.

Um, right. This is just a way of introducing it as far as i's concerned. 

[01:05:22] **Nathan Wrigley:** Okay. So a, a bright future for the year 2026 for the, the, the newly titled Dom Web show. The Dumb Web Show. We should talk about that. That's actually a, I think that's quite an interesting title. Um, but anyway, we'll see, uh, maybe we're already captured by our title and the SEO and the Google.

The Google search listings that go with what we've already done. But, um, I guess that's, that wraps it up for this particular one. Yeah. Does it? Yeah. Yeah. It was a long one. Yeah, it was a long one. Um, but thank you. Um, so the year 2026 begins with a bang for this show. There's, uh, there's an awful lot of stuff that we would like to leave behind, but we're giving ourselves the opportunity to do things differently in 2026.

Uh, David, anything you wanna say before I click the stop button? 

[01:06:10] **David Waumsley:** No. Thank you very much for your time today. Yeah. 

[01:06:12] **Nathan Wrigley:** You're very And everybody else who's got to the end. Yeah, yeah, yeah. The four people who've got to the end. Thank you very much for listening. We'll be back at some point in the near future.

Cheerio, Dave. Bye. 

</details> 